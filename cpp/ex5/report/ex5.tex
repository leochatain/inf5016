\documentclass{article}
\usepackage[brazil]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{times}
\usepackage{framed}
\usepackage{biblatex}
\usepackage{xcolor}
\usepackage{hyperref}

\title{Laboratório 5}
\author{Leonardo Chatain}

\begin{document}
\maketitle

\section{Tarefa}
Implementar três diferentes tabelas hash:

\begin{description}
 \item[Encadeamento] Nesta versão chaves que colidem são armazenadas na mesma posição na
tabela, em uma lista encadeada.

Para inserir basta calcular a posição (consideramos $O(1)$ o tempo de computar a função hash) e
adicionar o elemento no fim da fila ($O(1)$).

Para buscar uma chave nesta tabela é preciso percorrer a lista encadeada da posição
correspondente. O número esperado de comparações para o \emph{lookup} é $O(1 + N/M)$, com N
elementos na tabela de tamanho N.

 \item[Endereçamento aberto] Nesta versão, chaves que colidem são armazenadas em outras
posições da própria tabela. Na versão implementada (\emph{linear probing}), caso haja uma colisão,
tenta-se inserir a chave em posições subsequentes da tabela.

Com endereçamento aberto, tanto a inserção quanto a busca dependem do número de elementos inseridos
anteriormente (pois ambas devem percorrer a tabela buscando a posição de inserção). O número
esperado de operações é $1/\alpha * ln(1/1-\alpha)$.

 \item[Cuckoo hashing] Nesta versão existem duas funções hash. Uma chave está na tabela se ela
estiver em pelo menos uma das duas entradas correspondentes.

Para inserir a chave, caso haja uma colisão, ``chuta-se'' o elemento atual e insere-se o elemento
nessa posição. A seguir, tenta-se inserir o elemento chutado na sua outra posição (potencialmente
chutando outro elemento).

Casualmente haverá um ciclo na busca. Nesse caso, a tabela é reconstruida com novas entradas.

A busca é feita com apenas duas comparações. A inserção pode demorar mais, pois pode ser necessário
``chutar'' alguns elementos, ou mesmo reconstruir a tabela.

No meu experimento muitas vezes a tabela entrou em ``loop infinito''. Basicamente era preciso
recalcular a tabela, e no recálculo da tabela era preciso recalcular a tabela, e assim
indefinidamente. Isso depende da ocupação da tabela e do primo utilizado no cálculo da função hash.
Eu não sou capaz de explicar esse comportamento.

\end{description}

\section{Solução}

\subsection{Funções Hash}

As funções hash usadas são do seguinte tipo:

$$ H(x) = ((h_0 + h_1 * x + h_2 * x^2 + ... + h_n * x^n) mod P) mod M $$

Onde $n$ é o grau da função hash (pode ser escolhido), $M$ é o tamanho da tabela hash e P é um
primo ($P > M$).

Inicialmente usei como primo $2^{31} - 1$. Entretanto, com um primo muito maior que qualquer número
utilizado, o modulo P não acrescentava muita randomização ($ x mod P = x$ para $x < P$), e isso
causava loops muito frequentes na tabela cuckoo.

Entretanto, segundo o postulado de Bertrands, para todo número $n > 2$ existe um primo $p$ tal que
$n < p < 2 * n - 2$. Com isso podemos encontrar o menor primo maior que $M$ em $O(M)$ testes. Para
os testes, inicialmente quis usar o algoritmo de Miller-Rabin, mas como a busca por um primo só
seria feita na inicialização da tabela, optei por usar a solução simples $O(\sqrt{M})$.

No código, funções hash são calculadas pela classe \texttt{HashFunction}, e pode-se configurar o
grau da função, bem como a semente para randomização do polinômio (a mesma classe é usada em todas
as funções hash).

\section{Ambiente de teste}

Os resultados foram obtidos utilizando-se um \emph{Intel core i5}, com um processador de $2.27$ GHz
e $4$ GB de RAM.

\section{Resultados}

A seguir mostramos os resultados para diferentes ocupações das operações de insert (no código
\texttt{put}) e lookup (no código \texttt{contains}).

Os resultados são medidos em termos de acessos (quantos acessos são necessários para encontrar
(quando fazemos o lookup), ou quantos passos são necessários para inserir).

A medição de operações segue a seguinte metodologia: as tabelas tem tamanho $10000$. Para cada
tamanho são realizadas 100 operações (inserções e lookups de valores aleatórios), e a média é
tirada.

Os passos das operações são medidos com variáveis especiais no código.

É possível ver que o endereçamento aberto é de longe o pior dos métodos. Enquanto o encadeamento e
o cuckoo tem seus piores resultados com no maximo 10 passos, o endereçamento aberto pode chegar a
fazer quase 10000 (o número maximo de elementos) operações, tanto para inserção quanto para lookup.
É facil ver como isso é possível, visto que conforme a tabela vai ficando ``cheia'' é mais difícil
encontrar um espaço livre, e os últimos elementos inseridos precisam varrer praticamente toda a
tabela.

Porque os gráficos para endereçamento aberto ficaram muito pequenos (Figuras \ref{fig:put_open} e
\ref{fig:lookup_open}, ``zooms'' estão disponíveis nas figuras \ref{fig:put_open_zoom1},
\ref{fig:put_open_zoom2}, \ref{fig:lookup_open_zoom1} e \ref{fig:lookup_open_zoom2}.

Podemos claramente também ver que a melhor tabel para lookup é a Cuckoo (basta verificar as duas
posições) e a melhor para inserção é a encadeada (basta inserir no fim da lista encadeada). Ambas
tabelas tem custos constantes para as operações mencionadas, como pode ser visto nas figuras
\ref{fig:lookup_cuckoo} e \ref{fig:put_chaining}.

Uma questão interessante é que no cuckoo hashing, não houve nenhuma reconstrução de tabela (os
valores estão muito baixos, uma reconstrução tem custo N).

\begin{figure}
  \centering
  \includegraphics[width=\textwidth,keepaspectratio]{put_chaining}
  \caption{Operação de ``put'' em chaining.}
  \label{fig:put_chaining}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth,keepaspectratio]{put_open_all}
  \caption{Operação de ``put'' em open.}
  \label{fig:put_open}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth,keepaspectratio]{put_open_zoom1}
  \caption{Operação de ``lookup'' em open, apenas os valores menores que 1000.}
  \label{fig:put_open_zoom1}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth,keepaspectratio]{put_open_zoom2}
  \caption{Operação de ``lookup'' em open, apenas os valores menores que 100.}
  \label{fig:put_open_zoom2}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth,keepaspectratio]{put_cucko}
  \caption{Operação de ``put'' em cuckoo.}
  \label{fig:put_cuckoo}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth,keepaspectratio]{lookup_chaining}
  \caption{Operação de ``lookup'' em chaining.}
  \label{fig:lookup_chaining}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth,keepaspectratio]{lookup_open_all}
  \caption{Operação de ``lookup'' em open.}
  \label{fig:lookup_open}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth,keepaspectratio]{lookup_open_zoom1}
  \caption{Operação de ``lookup'' em open, apenas os valores menores que 1000.}
  \label{fig:lookup_open_zoom1}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth,keepaspectratio]{lookup_open_zoom2}
  \caption{Operação de ``lookup'' em open, apenas os valores menores que 100.}
  \label{fig:lookup_open_zoom2}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth,keepaspectratio]{lookup_cuckoo}
  \caption{Operação de ``lookup'' em cuckoo.}
  \label{fig:lookup_cuckoo}
\end{figure}

\section{Conclusões}

Pudemos ver que as complexidades das operações seguiu o esperado. Existem muitas outras variações
que poderiam ter sido analisadas (diferentes funções hash, diferentes graus para o polinômio da
tabela, variação do tipo de ``probing'' da tabela de endereçamento aberto (usei linear probing, mas
podia ser feito um probing quadrático ou hashing duplo, medir o tempo para ver o impacto da cache
nas diferentes técnicas), mas infelizmente não houve tempo para todas essas análises.

De forma geral é possível ver que as tabelas mais eficientes (dentre as estudadas aqui) são a
encadeada e a cuckoo. A escolha entre a encadeada e a cuckoo deve levar em conta qual o tipo de
operação mais frequente: cuckoo apresenta um tempo de lookup constante, mas pode ser cara na
inserção. Hashing com encadeamento, por outro lado, pode apresentar overhead no lookup, mas
apresenta tempo de inserção constante. Ambos os overheads não se comparam ao overhead de uma tabela
com endereçamento aberto.

Tabelas com endereçamento aberto logo se tornam ``saturadas'' e apresentam tempos de acesso muito
ruins.

\end{document}
